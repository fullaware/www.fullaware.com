[{"content":"Objective To have a single server with enough power to run nested vSphere 8 and Tanzu Kubernetes Grid with NSX. But with vSphere 8 I wanted to make sure I had something on the HCL. Dell PowerEdge R740 will carry the homelab moving forward.\nHardware  Dell PowerEdge R740  2 x Intel Xeon Gold 6132 2.6Ghz 14-Core 256GB RAM - 8 x 32GB 2400T DDR4 ECC H730p 2gb Cache Raid Controller PCIe 2x 1TB SSD in Raid 1 (Samsung 850) Broadcom 2x 10Gbe SFP / 2x 1Gbe Network Daughter Card (165T0) iDrac 9 Enterprise 2x 750w Platinum Power Supplies SABRENT NVMe M.2 SSD to PCIe Riser https://www.amazon.com/gp/product/B084GDY2PW/ WD_BLACK 2TB SN770 NVMe https://www.amazon.com/gp/product/B09QV5KJHV   Dell PowerEdge R720  2 x Intel(R) Xeon(R) CPU E5-2640 6-Core 128GB RAM - 16 x 8GB ECC PC3-12800 1333Mhz Replaced PERC 310 RAID Controller with LSI SAS 2008 flashed to IT mode. Replaced DVD with Samsung SSD 860 EVO 500GB, used as boot drive https://www.youtube.com/watch?v=Nx9-BK0WsxU    Software VMware vSphere 8 Licenses provided by VMUG Advantage membership\nConfiguration  Install ESXi 8 to 500GB SSD on R720.  YES I received the warning regarding unsupported CPU. This has yet to keep me from using vSphere 8 on this server. I did have to get creative with storage since my LSI2008 or PERC 310 aren\u0026rsquo;t supported. After installation I had 337.5GB for Datastore1 which I renamed to local_ssd500GB and have so far managed to squeeze 8 VMs onto it thanks to thin provisioning.   Install pi-hole on Ubuntu 22.04 LTS VM  Configure pi-hole with recursive DNS and add DNS entries for vCenter vm.   Install vCenter Enable PCIPassthrough for SAS2008 PCI-Express Fusion-MPT SAS-2 [Falcon] Install TrueNAS Core as a VM  Add SAS2008 HBA to VM as additional PCI device Add drives to be used as iSCSI target   Install vSphere 8 as VM Provision 4 new Ubuntu Server 22.04 VMs for Kubernetes  Manual Via Ansible - https://github.com/fullaware/k8s-iac#installing-kubernetes-2-installk8s   ","date":"2022-12-28","permalink":"https://www.fullaware.com/posts/homelab/","tags":["homelab","vmware"],"title":"Homelab"},{"content":"While working with Ansible for standing up a vanilla Kubernetes 1.25.5 cluster I found myself separating the the initial bootstrapping of the cluster, which includes intalling the CNI antrea from the rest of the configuration (metrics,metallb,contour) due to waiting for antrea to become Ready.\nFound this post from Fabian Lee\n# this wait for 'Available=True' only works for initial deployment, not rolling kubectl wait deployment -n default golang-hello-world-web --for condition=Available=True --timeout=90s # wait using 'rollout status' kubectl rollout status deployment golang-hello-world-web -n default --timeout=90s ","date":"2022-12-24","permalink":"https://www.fullaware.com/posts/k8s-wait/","tags":["k8s"],"title":"K8s Waiting for Condition=Available=True"},{"content":"Future home of Kubernetes, Python, VMware and homelab efforts.\nJoin me as I share my attempts at:\n Upgrade a Dell R720 with NVME storage and ESXi 8. Provisioning Kubernetes clusters using Ansible. Maintaining a Python webapp microservice for mining asteroids. Any technology tips I discover along the way.  ","date":"2022-12-23","permalink":"https://www.fullaware.com/posts/comingsoon/","tags":["homelab","k8s","python","vmware"],"title":"Coming Soon"}]