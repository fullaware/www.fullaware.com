[{"content":"Overview While writing Tagging Asteroids with MongoDB I was able to quickly provision a cluster on the free tier of MongoDB Atlas. What I originally wanted was to quickly stand up a MongoDB instance in my Kubernetes environment but found most documentation too complex for my usecase. Just give me a MongoDB \u0026ldquo;dialtone\u0026rdquo; as quickly as possible without having to install the binaries on my system.\nNOTE: This deployment pattern should not be used in production. Strongly recommend a StatefulSet for MongoDB Replica Sets.\nEasiest way to standup Kubernetes as a Developer Install Docker on your machine then install kind\nManifests You will find all the code for this deployment on my GitHub https://github.com/fullaware/k8s-mongodb\nKustomize The kustomization.yaml is the entrypoint to deploying MongoDB on Kubernetes. Kustomize allows us to package up all the other manifests (yaml files) and deploy them to a specific namespace (mongodb in this case). Kustomize also allows us to generate secrets so that we don\u0026rsquo;t have to do the base64 encoding by hand. In a production environment you would use something like Hashicorp Vault to centrally store passwords.\napiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization namespace: mongodb resources: - mongodb-namespace.yaml # Create MongoDB namespace - mongodb-dbinit-configmap.yaml # Initialize DB with data - mongodb-pvc.yaml # Request storage - mongodb-svc.yaml # Expose MongoDB as service - mongodb-deployment.yaml # Deploy container secretGenerator: - name: mongo-creds literals: - username=admin # MONGO_INITDB_ROOT_USERNAME - password=Candy123 # MONGO_INITDB_ROOT_PASSWORD Initialize MongoDB container with data using a configmap I prefer this method for it\u0026rsquo;s simplicity but comes with a major downside. You are limited to 1MB due to the objects size in etcd. If you need to initialize the database with more than 1MB, consider using an Init Container to download a mongodump file then mongorestore the file into the database.\nThe MongoDB image on Docker Hub will look for all scripts found in its mountpoint at /docker-entrypoint-initdb.d and execute them in alphabetical order.\nCreate a configmap and populate the data with the contents of a dbinit.js file like so [truncated for easier reading, see mongodb-dbinit-configmap.yaml]:\napiVersion: v1 kind: ConfigMap metadata: name: dbinit-script data: dbinit.js: |- db = new Mongo().getDB(\u0026quot;asteroids\u0026quot;); db.createCollection('asteroids', { capped: false }); db.asteroids.insert([{ \u0026quot;_id\u0026quot;: 1000, \u0026quot;name\u0026quot;: \u0026quot;Bennu\u0026quot;, \u0026quot;elements\u0026quot;: [ 100, 101, 108 ] }]) Persistent Volume Claim For our usecase we don\u0026rsquo;t want our data to disappear when we restart the deployment so we want to create a persistent volume claim.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: mongo-data spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi Service Here we will expose the MongoDB deployment as a service on port 27017. This will make it accessible to other applications running on the Kubernetes cluster.\napiVersion: v1 kind: Service metadata: labels: app: mongodb name: mongodb-svc spec: ports: - port: 27017 protocol: TCP targetPort: 27017 selector: app: mongodb type: ClusterIP Deployment All of our hard work comes together in the deployment. Here we will map our persistent volume for our /data/db as well as our dbinit-script configmap. Default username and password are provided by the secret that Kustomize generated earlier.\napiVersion: apps/v1 kind: Deployment metadata: labels: app: mongodb name: mongodb spec: replicas: 1 selector: matchLabels: app: mongodb strategy: {} template: metadata: labels: app: mongodb spec: containers: - image: mongo name: mongo args: [\u0026quot;--dbpath\u0026quot;,\u0026quot;/data/db\u0026quot;] env: - name: MONGO_INITDB_ROOT_USERNAME valueFrom: secretKeyRef: name: mongo-creds key: username - name: MONGO_INITDB_ROOT_PASSWORD valueFrom: secretKeyRef: name: mongo-creds key: password volumeMounts: - name: \u0026quot;mongo-data-dir\u0026quot; mountPath: \u0026quot;/data/db\u0026quot; - name: dbinit-script mountPath: /docker-entrypoint-initdb.d volumes: - name: \u0026quot;mongo-data-dir\u0026quot; persistentVolumeClaim: claimName: \u0026quot;mongo-data\u0026quot; - name: dbinit-script configMap: name: dbinit-script Running MongoDB on Kubernetes git clone https://github.com/fullaware/k8s-mongodb.git cd k8s-mongodb This next part is important, notice we will use a -k instead of -f which instructs kubectl to run the kustomization.yaml instead of just running all the yaml files in the folder.\nkubectl apply -k . Verify MongoDB server First get shell access into the deployment.\nkubectl exec deployment/mongodb -n mongodb -it -- /bin/bash Then auth into the server\nmongosh -u admin -p Candy123 Exit mongosh then exit from the deployment because now we want to access the MongoDB instance using either our programming language of choice, MongoDB Compass or mongosh from our local machine.\nAccess deployment on localhost Use kubectl to forward the port 27017 from the mongodb-svc to localhost\nkubectl port-forward --address 0.0.0.0 svc/mongodb-svc 27017:27017 -n mongodb From there we should be able to use mongosh client to connect to the MongoDB instance by connecting to localhost\nmongosh -u admin -p Candy123 Once we are in the Mongo Shell, let\u0026rsquo;s look for databases\ntest\u0026gt; show dbs admin 100.00 KiB asteroids 80.00 KiB config 72.00 KiB local 72.00 KiB Now use the asteroids database\ntest\u0026gt; use asteroids switched to db asteroids Next we will look at the collections in this database\nasteroids\u0026gt; show collections asteroids elements Find all the documents in the asteroids collection\nasteroids\u0026gt; db.asteroids.find() [ { _id: 1000, name: 'Bennu', elements: [ 100, 101, 108 ] }, { _id: 1001, name: 'Ceres', elements: [ 106, 103, 108 ] }, { _id: 1002, name: 'Pallas', elements: [ 103, 102, 105 ] }, { _id: 1003, name: 'Juno', elements: [ 107, 106, 100 ] }, { _id: 1004, name: 'Vesta', elements: [ 108, 101, 103 ] }, { _id: 1005, name: 'Astraea', elements: [ 105, 101, 106 ] } ] ","date":"2023-02-21","permalink":"http://www.fullaware.com/posts/k8smongodb/","tags":["mongodb","k8s"],"title":"MongoDB Kubernetes Deployment"},{"content":"Objective Let\u0026rsquo;s use MongoDB to build an asteroid tagging engine that allows us to assign multiple elements to any asteroid then query based on those elements.\nSchema design Arrays allow you to assign an arbitrary number of elements to a document. MongoDB allows you to insert, update and delete elements within arrays.\nA requirement of our tagging engine is we want to be able to change the name of the element without having to update each document with the new name. For this we will be keeping the element labels in a separate collection and reference them by _id just as we would in a SQL database. This works out great when we want to add metadata to the elements such as atomic weight or symbol.\nCollection : Elements For this example we will use simple _id numbers instead of ObjectIds.\n{ \u0026quot;_id\u0026quot; : 100, \u0026quot;label\u0026quot; : \u0026quot;iron\u0026quot; },{ \u0026quot;_id\u0026quot; : 101, \u0026quot;label\u0026quot; : \u0026quot;nickel\u0026quot; },{ \u0026quot;_id\u0026quot; : 102, \u0026quot;label\u0026quot; : \u0026quot;cobalt\u0026quot; },{ \u0026quot;_id\u0026quot; : 103, \u0026quot;label\u0026quot; : \u0026quot;platinum\u0026quot; },{ \u0026quot;_id\u0026quot; : 104, \u0026quot;label\u0026quot; : \u0026quot;olivine\u0026quot; },{ \u0026quot;_id\u0026quot; : 105, \u0026quot;label\u0026quot; : \u0026quot;potassium\u0026quot; },{ \u0026quot;_id\u0026quot; : 106, \u0026quot;label\u0026quot; : \u0026quot;silicon\u0026quot; },{ \u0026quot;_id\u0026quot; : 107, \u0026quot;label\u0026quot; : \u0026quot;magnesium\u0026quot; },{ \u0026quot;_id\u0026quot; : 108, \u0026quot;label\u0026quot; : \u0026quot;phosphorus\u0026quot; },{ \u0026quot;_id\u0026quot; : 109, \u0026quot;label\u0026quot; : \u0026quot;silver\u0026quot; },{ \u0026quot;_id\u0026quot; : 110, \u0026quot;label\u0026quot; : \u0026quot;gold\u0026quot; } Collection : Asteroids { \u0026quot;_id\u0026quot; : 1000, \u0026quot;name\u0026quot; : \u0026quot;Bennu\u0026quot;, \u0026quot;elements\u0026quot; : [100, 101, 108] },{ \u0026quot;_id\u0026quot; : 1001, \u0026quot;name\u0026quot; : \u0026quot;Ceres\u0026quot;, \u0026quot;elements\u0026quot; : [106, 103, 108] },{ \u0026quot;_id\u0026quot; : 1002, \u0026quot;name\u0026quot; : \u0026quot;Pallas\u0026quot;, \u0026quot;elements\u0026quot; : [103, 102, 105] },{ \u0026quot;_id\u0026quot; : 1003, \u0026quot;name\u0026quot; : \u0026quot;Juno\u0026quot;, \u0026quot;elements\u0026quot; : [107, 106, 100] },{ \u0026quot;_id\u0026quot; : 1004, \u0026quot;name\u0026quot; : \u0026quot;Vesta\u0026quot;, \u0026quot;elements\u0026quot; : [108, 101, 103] },{ \u0026quot;_id\u0026quot; : 1005, \u0026quot;name\u0026quot; : \u0026quot;Astraea\u0026quot;, \u0026quot;elements\u0026quot; : [105, 101, 106] } $lookup - MongoDB JOIN [ { '$lookup': { 'from': 'elements', 'localField': 'elements', 'foreignField': '_id', 'as': 'result' } } ] Returns all asteroid documents with the cooresponding element names from the elements collection. Example:\n{ \u0026quot;_id\u0026quot;: 1000, \u0026quot;name\u0026quot;: \u0026quot;Bennu\u0026quot;, \u0026quot;elements\u0026quot;: [ 100, 101, 108 ], \u0026quot;result\u0026quot;: [ { \u0026quot;_id\u0026quot;: 100, \u0026quot;label\u0026quot;: \u0026quot;iron\u0026quot; }, { \u0026quot;_id\u0026quot;: 101, \u0026quot;label\u0026quot;: \u0026quot;nickel\u0026quot; }, { \u0026quot;_id\u0026quot;: 108, \u0026quot;label\u0026quot;: \u0026quot;phosphorus\u0026quot; } ] } This pattern allows us to rename the element labels as needed without having to update the 1000\u0026rsquo;s of asteroids with that specific element name. This model is certainly DRY [Don\u0026rsquo;t Repeat Yourself] as well as very SQL like, having a foreign key relationship from the elements array to the Elements collection.\nFind the nickel Find all the asteroids that are known to have nickel in them.\n[ { '$match': { 'label': 'nickel' } }, { '$lookup': { 'from': 'asteroids', 'localField': '_id', 'foreignField': 'elements', 'as': 'asteroids' } } ] Returns the element document with each of the asteroids embedded in the asteroids array.\n{ \u0026quot;_id\u0026quot;: 101, \u0026quot;label\u0026quot;: \u0026quot;nickel\u0026quot;, \u0026quot;asteroids\u0026quot;: [ { \u0026quot;_id\u0026quot;: 1000, \u0026quot;name\u0026quot;: \u0026quot;Bennu\u0026quot;, \u0026quot;elements\u0026quot;: [ 100, 101, 108 ] }, { \u0026quot;_id\u0026quot;: 1004, \u0026quot;name\u0026quot;: \u0026quot;Vesta\u0026quot;, \u0026quot;elements\u0026quot;: [ 108, 101, 103 ] }, { \u0026quot;_id\u0026quot;: 1005, \u0026quot;name\u0026quot;: \u0026quot;Astraea\u0026quot;, \u0026quot;elements\u0026quot;: [ 105, 101, 106 ] } ] } Inserting multiple elements into an array According to the document, we see that the asteroid Bennu is made up of iron, nickel, and phosphorus. Let\u0026rsquo;s add a couple more elements like silver and gold.\nWe will do this by using the MongoDB operator $addToSet.\ndb.asteroids.update_one( {\u0026quot;_id\u0026quot;: 1000}, {\u0026quot;$addToSet\u0026quot;: { \u0026quot;elements\u0026quot;: { \u0026quot;$each\u0026quot;: [109,110]}}}) Gold streak Lets imagine new sensor technology has allowed us to find gold in not one but MULTIPLE asteroids, let\u0026rsquo;s update the collection with this new information! We are going to reuse the $addToSet operator here so that if we wanted to add multiple elements to multiple asteroids, we could totally do so.\ndb.asteroids.update_many( { '_id': { '$in': [ 1002, 1003 ] } }, {\u0026quot;$addToSet\u0026quot;: { \u0026quot;elements\u0026quot;: { \u0026quot;$each\u0026quot;: [110]}}}) Mistakes happen Sometimes the sensors are all wrong, let\u0026rsquo;s delete this element from those asteroids. Again I\u0026rsquo;m going to use an operator that allows you to delete multiple elements from multiple asteroids. In this case we are only going to delete 110 from asteroids 1002 and 1003.\ndb.asteroids.update_many( { '_id': { '$in': [ 1002, 1003 ] } }, {\u0026quot;$pull\u0026quot;: { \u0026quot;elements\u0026quot;: { \u0026quot;$in\u0026quot;: [110]}}}) ","date":"2023-02-15","permalink":"http://www.fullaware.com/posts/mongodbtags/","tags":["mongodb"],"title":"Tagging Asteroids with MongoDB"},{"content":"Firefox 108.0.1 (64-bit) - \u0026ldquo;The WidevineCdm plugin has crashed\u0026rdquo;\nWhile studying for my CKAD on Udemy over the holidays I encountered this error when attempting to open ANYTHING that had DRM protected video; Udemy, Netflix, Hulu, etc. Some recommended fixes included maintaining a separate firefox binary. Luckily I found the fix on AskUbuntu.com\nEdited /etc/apparmor.d/usr.bin.firefox :\nBelow the line:\n# per-user firefox configuration Insert the line:\nowner @{HOME}/.{firefox,mozilla}/**/gmp-widevinecdm/**/libwidevinecdm.so m, After that, you can reboot your computer (or reload AppArmor\u0026rsquo;s rules with:\napparmor_parser --replace /etc/apparmor.d/usr.bin.firefox ","date":"2022-12-31","permalink":"http://www.fullaware.com/posts/firefoxwildvine/","tags":["linux"],"title":"Firefox: The WidevineCdm plugin has crashed"},{"content":"In order to access Kubernetes applications via my ingress projectcontour.io, I\u0026rsquo;ll use a wildcard DNS entry.\nUnfortunately this isn\u0026rsquo;t a simple entry in the web UI for Pi-hole (yet?). A quick search and Brandon Rozek had documented the steps to add a wildcard DNS entry in dnsmasq.\nFirst, lets get the External-IP of our envoy LoadBalancer service. Mine shows as 10.28.28.80.\nkubectl get service envoy -n projectcontour NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE envoy LoadBalancer 10.103.158.9 10.28.28.80 80:32032/TCP,443:31610/TCP 43h Next we will need to SSH into our Pi-Hole and create a new config file located at /etc/dnsmasq.d/03-custom-dns.conf\naddress=/k8s.home.fullaware.com/10.28.28.80 Next let\u0026rsquo;s restart Pi-Hole service to reload the new config.\nsudo systemctl restart pihole-FTL Now when I dig for the k8s.home.fullaware.com domain it comes up with the IP address of the envoy LoadBalancer.\n;; QUESTION SECTION: ;k8s.home.fullaware.com. IN A ;; ANSWER SECTION: k8s.home.fullaware.com. 0 IN A 10.28.28.80 This allows me to create an ingress with the name asteroids.k8s.home.fullaware.com to point to my hosted app asteroids.\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: asteroids-app namespace: asteroids spec: rules: - host: asteroids.k8s.home.fullaware.com http: paths: - pathType: Prefix path: \u0026quot;/\u0026quot; backend: service: name: asteroids-app port: number: 8080 ","date":"2022-12-30","permalink":"http://www.fullaware.com/posts/piholewildcarddns/","tags":["homelab","k8s"],"title":"Pi-Hole Wildcard DNS"},{"content":"Objective To have a single server with enough power to run nested vSphere 8 and Tanzu Kubernetes Grid with NSX. But with vSphere 8 I wanted to make sure I had something on the HCL. Dell PowerEdge R740 will carry the homelab moving forward.\nHardware Dell PowerEdge R740 2 x Intel Xeon Gold 6132 2.6Ghz 14-Core 256GB RAM - 8 x 32GB 2400T DDR4 ECC H730p 2gb Cache Raid Controller PCIe 2x 1TB SSD in Raid 1 (Samsung 850) Broadcom 2x 10Gbe SFP / 2x 1Gbe Network Daughter Card (165T0) iDrac 9 Enterprise 2x 750w Platinum Power Supplies SABRENT NVMe M.2 SSD to PCIe Riser https://www.amazon.com/gp/product/B084GDY2PW/ WD_BLACK 2TB SN770 NVMe https://www.amazon.com/gp/product/B09QV5KJHV Dell PowerEdge R720 2 x Intel(R) Xeon(R) CPU E5-2640 6-Core 128GB RAM - 16 x 8GB ECC PC3-12800 1333Mhz Replaced PERC 310 RAID Controller with LSI SAS 2008 flashed to IT mode. Replaced DVD with Samsung SSD 860 EVO 500GB, used as boot drive https://www.youtube.com/watch?v=Nx9-BK0WsxU Software VMware vSphere 8 Licenses provided by VMUG Advantage membership\nConfiguration of R720 Install ESXi 8 to 500GB SSD on R720. YES I received the warning regarding unsupported CPU. This has yet to keep me from using vSphere 8 on this server. I did have to get creative with storage since my LSI2008 or PERC 310 aren\u0026rsquo;t supported. After installation I had 337.5GB for Datastore1 which I renamed to local_ssd500GB and have so far managed to squeeze 9 VMs onto it thanks to thin provisioning. Install pi-hole on Ubuntu 22.04 LTS VM Configure pi-hole with recursive DNS and add DNS entries for vCenter vm. Install vCenter Enable PCIPassthrough for SAS2008 PCI-Express Fusion-MPT SAS-2 [Falcon] Install TrueNAS Core as a VM Add SAS2008 HBA to VM as additional PCI device Add drives to be used as iSCSI target Install vSphere 8 as VM Provision 4 new Ubuntu Server 22.04 VMs for Kubernetes Manual Via Ansible - https://github.com/fullaware/k8s-iac#installing-kubernetes-2-installk8s Configuration of R740 coming soon","date":"2022-12-29","permalink":"http://www.fullaware.com/posts/homelab/","tags":["homelab","vmware"],"title":"Homelab"},{"content":"While working with Ansible for standing up a vanilla Kubernetes 1.25.5 cluster I found myself separating the the initial bootstrapping of the cluster, which includes intalling the CNI antrea from the rest of the configuration (metrics,metallb,contour) due to waiting for antrea to become Ready.\nFound this post from Fabian Lee\n# this wait for 'Available=True' only works for initial deployment, not rolling kubectl wait deployment -n default golang-hello-world-web --for condition=Available=True --timeout=90s # wait using 'rollout status' kubectl rollout status deployment golang-hello-world-web -n default --timeout=90s ","date":"2022-12-24","permalink":"http://www.fullaware.com/posts/k8s-wait/","tags":["k8s"],"title":"K8s Waiting for Condition=Available=True"},{"content":"Future home of Kubernetes, Python, VMware and homelab efforts.\nJoin me as I share my attempts at:\nUpgrade a Dell R720 with NVME storage and ESXi 8. Provisioning Kubernetes clusters using Ansible. Maintaining a Python webapp microservice for mining asteroids. Any technology tips I discover along the way. ","date":"2022-12-23","permalink":"http://www.fullaware.com/posts/comingsoon/","tags":["homelab","k8s","python","vmware"],"title":"Coming Soon"}]